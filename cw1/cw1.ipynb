{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Neural Networks CW1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Approach\n",
    "This courswork follows the 'universal approach of machine learning' by Cholet. The approach can be assembled by the following steps:\n",
    "1. Defining the problem and assembling the data\n",
    "2. Choosing a measure of success\n",
    "3. Defining an evaluation protocol\n",
    "4. Preparing the data\n",
    "5. Developing a model\n",
    "6. Scaling - Ovefit the Model\n",
    "7. Regularize model and hyperparamter tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "\n",
    "Based on my personal interest in digital health, the question, how to leverage medcinine often comes up. At the times of ChatGPT the term AI is present everywhere. Especially in the field of modern medicin, physicians and scientis search approaches to upscale medicine and make it more efficient. The key problem of scaling up is that one physician can take care of one patient at the time. But what would be if multiple patients could be helped at the same time. That is the point where AI comes along as all healing solution. Following this path forcibly it has to proven how trustworthy these kind of solutions are. Personally I can image that the fields of A.I. and machine learning are going to enter medicine step by step in minor fields to achieve a higher grade of automation e.g. evaluating X-ray images.\n",
    "\n",
    "\n",
    "## 1. Definition of the Problem\n",
    "\n",
    "In this coursework I would like to build a neural network to predict the presents of a heart disease. As input data serves a dataset downloaded from Kaggle. The dataset is called 'Heart Failure Prediction Dataset'. The aim is to predict, based on the given data, whether a heart disease is present. This results in the problem of binary classification. In this context, the hypothesis is: Based on the given medical observations like 'resting blood preasure' and 'chest pain type' it can be predicted if a heart disease is present.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Defining a Measure of Success\n",
    "\n",
    "In order to evaluate the results of the model built in this notebook a measure of success needs to be defined. As mentioned in the previous section the aim is to solve a binary classification model. In dependence of the data distribution accuracy and area under the receiver operating characteristics curve (ROC, AUC) are suitable metrics.\n",
    "\n",
    "Particularly the ROC, AUC is a good measure of success. The ROC (receiver operating characteristics curve) is a graphical representation to evaluate the binary classifier. To create the ROC the true positive rate (TPR) and false positive rate (FPR) is needed. The curve for the ROC is created by plotting TPR, FPR against each other.\n",
    "\n",
    "An additional measure for ROC is the 'Area Under the Curve' (AUC). It measures the entire two-dimensional area under the ROC. It is measure of all possible classification tresh holds. An AUC of 1 would represent a perfect classifier while an AUC of 0.5 would represent a useless classifier.\n",
    "\n",
    "The higher the ROC to th upper left corner, the higher is the overall accuracy. A line with a roughly 45 degree diagonal would represent a classifier with very limited discrimination ability.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Defining an evaluation protocol"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# defining relative path to file\n",
    "file= './data/heart.csv'\n",
    "\n",
    "# read file as pandas dataframe\n",
    "df= pd.read_csv(file, sep=',', header= 0) # define seperator as ','"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n0   40   M           ATA        140          289          0     Normal    172   \n1   49   F           NAP        160          180          0     Normal    156   \n2   37   M           ATA        130          283          0         ST     98   \n3   48   F           ASY        138          214          0     Normal    108   \n4   54   M           NAP        150          195          0     Normal    122   \n5   39   M           NAP        120          339          0     Normal    170   \n6   45   F           ATA        130          237          0     Normal    170   \n7   54   M           ATA        110          208          0     Normal    142   \n8   37   M           ASY        140          207          0     Normal    130   \n9   48   F           ATA        120          284          0     Normal    120   \n\n  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n0              N      0.0       Up             0  \n1              N      1.0     Flat             1  \n2              N      0.0       Up             0  \n3              Y      1.5     Flat             1  \n4              N      0.0       Up             0  \n5              N      0.0       Up             0  \n6              N      0.0       Up             0  \n7              N      0.0       Up             0  \n8              Y      1.5     Flat             1  \n9              N      0.0       Up             0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>ChestPainType</th>\n      <th>RestingBP</th>\n      <th>Cholesterol</th>\n      <th>FastingBS</th>\n      <th>RestingECG</th>\n      <th>MaxHR</th>\n      <th>ExerciseAngina</th>\n      <th>Oldpeak</th>\n      <th>ST_Slope</th>\n      <th>HeartDisease</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40</td>\n      <td>M</td>\n      <td>ATA</td>\n      <td>140</td>\n      <td>289</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>172</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>49</td>\n      <td>F</td>\n      <td>NAP</td>\n      <td>160</td>\n      <td>180</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>156</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>Flat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>37</td>\n      <td>M</td>\n      <td>ATA</td>\n      <td>130</td>\n      <td>283</td>\n      <td>0</td>\n      <td>ST</td>\n      <td>98</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48</td>\n      <td>F</td>\n      <td>ASY</td>\n      <td>138</td>\n      <td>214</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>108</td>\n      <td>Y</td>\n      <td>1.5</td>\n      <td>Flat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54</td>\n      <td>M</td>\n      <td>NAP</td>\n      <td>150</td>\n      <td>195</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>122</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>39</td>\n      <td>M</td>\n      <td>NAP</td>\n      <td>120</td>\n      <td>339</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>170</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>45</td>\n      <td>F</td>\n      <td>ATA</td>\n      <td>130</td>\n      <td>237</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>170</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>54</td>\n      <td>M</td>\n      <td>ATA</td>\n      <td>110</td>\n      <td>208</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>142</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>37</td>\n      <td>M</td>\n      <td>ASY</td>\n      <td>140</td>\n      <td>207</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>130</td>\n      <td>Y</td>\n      <td>1.5</td>\n      <td>Flat</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>48</td>\n      <td>F</td>\n      <td>ATA</td>\n      <td>120</td>\n      <td>284</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>120</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation that data was load correctly\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'Sex', 'ChestPainType', 'RestingBP', 'Cholesterol', 'FastingBS',\n",
      "       'RestingECG', 'MaxHR', 'ExerciseAngina', 'Oldpeak', 'ST_Slope',\n",
      "       'HeartDisease'],\n",
      "      dtype='object')\n",
      "Number of columns: 12\n"
     ]
    }
   ],
   "source": [
    "# check the columns of the dataframe\n",
    "columns= df.columns\n",
    "print(columns)\n",
    "print(f'Number of columns: {len(columns)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The column above shows the columns of the data frame. In total the dataframe has 12 columns. The column 'HeartDisease' is the target column that is supposed.\n",
    "In the following step the divided in feature columns and the target column."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# divide dataframe into featues and labels\n",
    "df_train = df.iloc[:, :len(df.columns)-1]\n",
    "df_label= df.iloc[:,-1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n0   40   M           ATA        140          289          0     Normal    172   \n1   49   F           NAP        160          180          0     Normal    156   \n2   37   M           ATA        130          283          0         ST     98   \n3   48   F           ASY        138          214          0     Normal    108   \n4   54   M           NAP        150          195          0     Normal    122   \n\n  ExerciseAngina  Oldpeak ST_Slope  \n0              N      0.0       Up  \n1              N      1.0     Flat  \n2              N      0.0       Up  \n3              Y      1.5     Flat  \n4              N      0.0       Up  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>ChestPainType</th>\n      <th>RestingBP</th>\n      <th>Cholesterol</th>\n      <th>FastingBS</th>\n      <th>RestingECG</th>\n      <th>MaxHR</th>\n      <th>ExerciseAngina</th>\n      <th>Oldpeak</th>\n      <th>ST_Slope</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40</td>\n      <td>M</td>\n      <td>ATA</td>\n      <td>140</td>\n      <td>289</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>172</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>49</td>\n      <td>F</td>\n      <td>NAP</td>\n      <td>160</td>\n      <td>180</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>156</td>\n      <td>N</td>\n      <td>1.0</td>\n      <td>Flat</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>37</td>\n      <td>M</td>\n      <td>ATA</td>\n      <td>130</td>\n      <td>283</td>\n      <td>0</td>\n      <td>ST</td>\n      <td>98</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48</td>\n      <td>F</td>\n      <td>ASY</td>\n      <td>138</td>\n      <td>214</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>108</td>\n      <td>Y</td>\n      <td>1.5</td>\n      <td>Flat</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54</td>\n      <td>M</td>\n      <td>NAP</td>\n      <td>150</td>\n      <td>195</td>\n      <td>0</td>\n      <td>Normal</td>\n      <td>122</td>\n      <td>N</td>\n      <td>0.0</td>\n      <td>Up</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "0    0\n1    1\n2    0\n3    1\n4    0\nName: HeartDisease, dtype: int64"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 918 entries, 0 to 917\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Age             918 non-null    int64  \n",
      " 1   Sex             918 non-null    object \n",
      " 2   ChestPainType   918 non-null    object \n",
      " 3   RestingBP       918 non-null    int64  \n",
      " 4   Cholesterol     918 non-null    int64  \n",
      " 5   FastingBS       918 non-null    int64  \n",
      " 6   RestingECG      918 non-null    object \n",
      " 7   MaxHR           918 non-null    int64  \n",
      " 8   ExerciseAngina  918 non-null    object \n",
      " 9   Oldpeak         918 non-null    float64\n",
      " 10  ST_Slope        918 non-null    object \n",
      " 11  HeartDisease    918 non-null    int64  \n",
      "dtypes: float64(1), int64(6), object(5)\n",
      "memory usage: 86.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check the quality of the data\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The datasets consists of 918 observations. On first sight it seems to be that there a no missing values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "HeartDisease\n1    0.553377\n0    0.446623\nName: proportion, dtype: float64"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the class distribution of the target column\n",
    "df.HeartDisease.value_counts(normalize= True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The target class is distrbuted in 55% observations that related ti a heart disease and 44% without heart disease. This gets quite close to an almost equal distribution. So the target class is well balanced."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "              Age   RestingBP  Cholesterol   FastingBS       MaxHR  \\\ncount  918.000000  918.000000   918.000000  918.000000  918.000000   \nmean    53.510893  132.396514   198.799564    0.233115  136.809368   \nstd      9.432617   18.514154   109.384145    0.423046   25.460334   \nmin     28.000000    0.000000     0.000000    0.000000   60.000000   \n25%     47.000000  120.000000   173.250000    0.000000  120.000000   \n50%     54.000000  130.000000   223.000000    0.000000  138.000000   \n75%     60.000000  140.000000   267.000000    0.000000  156.000000   \nmax     77.000000  200.000000   603.000000    1.000000  202.000000   \n\n          Oldpeak  HeartDisease  \ncount  918.000000    918.000000  \nmean     0.887364      0.553377  \nstd      1.066570      0.497414  \nmin     -2.600000      0.000000  \n25%      0.000000      0.000000  \n50%      0.600000      1.000000  \n75%      1.500000      1.000000  \nmax      6.200000      1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>RestingBP</th>\n      <th>Cholesterol</th>\n      <th>FastingBS</th>\n      <th>MaxHR</th>\n      <th>Oldpeak</th>\n      <th>HeartDisease</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>918.000000</td>\n      <td>918.000000</td>\n      <td>918.000000</td>\n      <td>918.000000</td>\n      <td>918.000000</td>\n      <td>918.000000</td>\n      <td>918.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>53.510893</td>\n      <td>132.396514</td>\n      <td>198.799564</td>\n      <td>0.233115</td>\n      <td>136.809368</td>\n      <td>0.887364</td>\n      <td>0.553377</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>9.432617</td>\n      <td>18.514154</td>\n      <td>109.384145</td>\n      <td>0.423046</td>\n      <td>25.460334</td>\n      <td>1.066570</td>\n      <td>0.497414</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>60.000000</td>\n      <td>-2.600000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>47.000000</td>\n      <td>120.000000</td>\n      <td>173.250000</td>\n      <td>0.000000</td>\n      <td>120.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>54.000000</td>\n      <td>130.000000</td>\n      <td>223.000000</td>\n      <td>0.000000</td>\n      <td>138.000000</td>\n      <td>0.600000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>60.000000</td>\n      <td>140.000000</td>\n      <td>267.000000</td>\n      <td>0.000000</td>\n      <td>156.000000</td>\n      <td>1.500000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>77.000000</td>\n      <td>200.000000</td>\n      <td>603.000000</td>\n      <td>1.000000</td>\n      <td>202.000000</td>\n      <td>6.200000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows descriptive statistics for numeric columns\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The describe function of the dataframe gives a statical overview of the numeric columns. Firstly there are no missing values. Secondly it can be noted that the scale of the data has big differences. This becomes clear comparing values like 'Age' and 'Cholesterol'. This shows scaling gets necessary."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "Age               0\nSex               0\nChestPainType     0\nRestingBP         0\nCholesterol       0\nFastingBS         0\nRestingECG        0\nMaxHR             0\nExerciseAngina    0\nOldpeak           0\nST_Slope          0\ndtype: int64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null values\n",
    "df_train.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Scaling numeric values\n",
    "num_cols= ['Age', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR', 'Oldpeak']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Following the numeric coloumns of the datafram will be scaled\n",
    "for col in num_cols:\n",
    "    df_train[col] = (df_train[col] - df_train[col].mean()) / df_train[col].std()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Transform categorical variable into dummy variables; source: https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html\u001B[39;00m\n\u001B[1;32m      2\u001B[0m cat_cols\u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSex\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mChestPainType\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRestingECG\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExerciseAngina\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mST_Slope\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m----> 3\u001B[0m df_train\u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_dummies\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcat_cols\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m df_train\u001B[38;5;241m.\u001B[39mSex_M\u001B[38;5;241m.\u001B[39minfo\n",
      "File \u001B[0;32m~/PycharmProjects/DSM150_NN/venv/lib/python3.10/site-packages/pandas/core/reshape/encoding.py:164\u001B[0m, in \u001B[0;36mget_dummies\u001B[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001B[0m\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInput must be a list-like for parameter `columns`\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 164\u001B[0m     data_to_encode \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;66;03m# validate prefixes and separator to avoid silently dropping cols\u001B[39;00m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcheck_len\u001B[39m(item, name: \u001B[38;5;28mstr\u001B[39m):\n",
      "File \u001B[0;32m~/PycharmProjects/DSM150_NN/venv/lib/python3.10/site-packages/pandas/core/frame.py:3899\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3897\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n\u001B[1;32m   3898\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[0;32m-> 3899\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcolumns\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m   3901\u001B[0m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n\u001B[1;32m   3902\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(indexer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n",
      "File \u001B[0;32m~/PycharmProjects/DSM150_NN/venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6114\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[0;34m(self, key, axis_name)\u001B[0m\n\u001B[1;32m   6111\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   6112\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[0;32m-> 6114\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   6116\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[1;32m   6117\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[1;32m   6118\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/DSM150_NN/venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6175\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[0;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[1;32m   6173\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m use_interval_msg:\n\u001B[1;32m   6174\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[0;32m-> 6175\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   6177\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[1;32m   6178\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyError\u001B[0m: \"None of [Index(['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Transform categorical variable into dummy variables; source: https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html\n",
    "cat_cols= ['Sex', 'ChestPainType','RestingECG','ExerciseAngina', 'ST_Slope']\n",
    "df_train= pd.get_dummies(df_train, columns=cat_cols)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hence applied the 'get_dummies' method from pandas the categorical data is is split in n boolean columns representing the number of unique values. Corresponding to the distritbution of the the orginial values. A appearance of the categorical value is stored as boolean value. The aim ist to change the boolean values into ones and zeros representing the boolean value."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "cat_cols= ['Sex_F', 'Sex_M', 'ChestPainType_ASY', 'ChestPainType_ATA', 'ChestPainType_NAP', 'ChestPainType_TA', 'RestingECG_LVH', 'RestingECG_Normal', 'RestingECG_ST', 'ExerciseAngina_N', 'ExerciseAngina_Y', 'ST_Slope_Down', 'ST_Slope_Flat', 'ST_Slope_Up']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "df_train[cat_cols]= df_train[cat_cols].astype(str)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-1.4323590105189488, 0.41068502452424355, 0.824620753758324,\n        -0.5510409629061659, 1.3821747828285678, -0.8319788750413097,\n        'False', 'True', 'False', 'True', 'False', 'False', 'False',\n        'True', 'False', 'True', 'False', 'False', 'False', 'True'],\n       [-0.4782229027299014, 1.490939616252769, -0.1718673610980285,\n        -0.5510409629061659, 0.7537462668036182, 0.10560596081422968,\n        'True', 'False', 'False', 'False', 'True', 'False', 'False',\n        'True', 'False', 'True', 'False', 'False', 'True', 'False'],\n       [-1.7504043797819644, -0.1294422713400192, 0.7697681969772403,\n        -0.5510409629061659, -1.524307103786824, -0.8319788750413097,\n        'False', 'True', 'False', 'True', 'False', 'False', 'False',\n        'False', 'True', 'True', 'False', 'False', 'False', 'True'],\n       [-0.5842380258175733, 0.302659565351391, 0.1389637939947787,\n        -0.5510409629061659, -1.1315392812712306, 0.5743983787419994,\n        'True', 'False', 'True', 'False', 'False', 'False', 'False',\n        'True', 'False', 'False', 'True', 'False', 'True', 'False'],\n       [0.05185271270845815, 0.9508123203885064, -0.034735969145319436,\n        -0.5510409629061659, -0.5816643297493996, -0.8319788750413097,\n        'False', 'True', 'False', 'False', 'True', 'False', 'False',\n        'True', 'False', 'True', 'False', 'False', 'False', 'True'],\n       [-1.5383741336066206, -0.669569567204282, 1.2817253936006874,\n        -0.5510409629061659, 1.3036212183254492, -0.8319788750413097,\n        'False', 'True', 'False', 'False', 'True', 'False', 'False',\n        'True', 'False', 'True', 'False', 'False', 'False', 'True'],\n       [-0.9022833950805891, -0.1294422713400192, 0.3492319283222659,\n        -0.5510409629061659, 1.3036212183254492, -0.8319788750413097,\n        'True', 'False', 'False', 'True', 'False', 'False', 'False',\n        'True', 'False', 'True', 'False', 'False', 'False', 'True'],\n       [0.05185271270845815, -1.2096968630685447, 0.08411123721369507,\n        -0.5510409629061659, 0.20387131528178734, -0.8319788750413097,\n        'False', 'True', 'False', 'True', 'False', 'False', 'False',\n        'True', 'False', 'True', 'False', 'False', 'False', 'True'],\n       [-1.7504043797819644, 0.41068502452424355, 0.07496914441684781,\n        -0.5510409629061659, -0.26745007173692487, 0.5743983787419994,\n        'False', 'True', 'True', 'False', 'False', 'False', 'False',\n        'True', 'False', 'False', 'True', 'False', 'True', 'False'],\n       [-0.5842380258175733, -0.669569567204282, 0.7789102897740876,\n        -0.5510409629061659, -0.6602178942525184, -0.8319788750413097,\n        'True', 'False', 'False', 'True', 'False', 'False', 'False',\n        'True', 'False', 'True', 'False', 'False', 'False', 'True']],\n      dtype=object)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_train= df_train.to_numpy()\n",
    "arr_train[:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 19:45:12.439280: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_model(learning_rate= .1, loss= 'binary_crossentropy', activation='relu'):\n",
    "    model= models.Sequential()\n",
    "    model.add(layers.Dense())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# References\n",
    "\n",
    "- Dataset: https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
